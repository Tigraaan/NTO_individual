# champion_ml_solution.py
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import Ridge
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error
import warnings
warnings.filterwarnings('ignore')

class ChampionMLPredictor:
    def __init__(self):
        self.models = {}
        self.scalers = {}
        self.encoders = {}
        self.feature_columns = []
        
    def load_all_data(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        print("üìÇ –ó–ê–ì–†–£–ó–ö–ê –í–°–ï–• –î–ê–ù–ù–´–•...")
        
        # –§—É–Ω–∫—Ü–∏—è –¥–ª—è —É–º–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
        def smart_load(filename):
            for sep in [';', ',', '\t']:
                try:
                    df = pd.read_csv(filename, sep=sep, encoding='utf-8')
                    if len(df.columns) > 1:
                        print(f"   ‚úÖ {filename}: {df.shape}")
                        return df
                except:
                    continue
            return None
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤
        train = smart_load('train.csv')
        test = smart_load('test.csv')
        books = smart_load('books.csv')
        users = smart_load('users.csv')
        genres = smart_load('genres.csv')
        book_genres = smart_load('book_genres.csv')
        book_descriptions = smart_load('book_descriptions.csv')
        
        return train, test, books, users, genres, book_genres, book_descriptions
    
    def create_comprehensive_features(self, df, books, users, book_genres, is_train=True):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö"""
        print("üîß –°–û–ó–î–ê–ù–ò–ï –ö–û–ú–ü–õ–ï–ö–°–ù–´–• –ü–†–ò–ó–ù–ê–ö–û–í...")
        
        # 1. –ë–ê–ó–û–í–´–ï –ü–†–ò–ó–ù–ê–ö–ò –ò–ó TRAIN
        if is_train:
            # –î–ª—è –æ–±—É—á–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–æ—á–∏—Ç–∞–Ω–Ω—ã–µ –∫–Ω–∏–≥–∏
            df = df[df['has_read'] == 1].copy()
        
        # 2. –°–¢–ê–¢–ò–°–¢–ò–ö–ò –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–ï–ô –ò –ö–ù–ò–ì
        if is_train:
            # User statistics
            self.user_stats = df.groupby('user_id').agg({
                'rating': ['mean', 'count', 'std', 'min', 'max', 'median']
            }).reset_index()
            self.user_stats.columns = ['user_id', 'user_mean', 'user_count', 'user_std', 'user_min', 'user_max', 'user_median']
            
            # Book statistics  
            self.book_stats = df.groupby('book_id').agg({
                'rating': ['mean', 'count', 'std', 'min', 'max', 'median']
            }).reset_index()
            self.book_stats.columns = ['book_id', 'book_mean', 'book_count', 'book_std', 'book_min', 'book_max', 'book_median']
            
            # Global statistics
            self.global_mean = df['rating'].mean()
            self.global_median = df['rating'].median()
            self.global_std = df['rating'].std()
        
        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞–º–∏
        df = df.merge(self.user_stats, on='user_id', how='left')
        df = df.merge(self.book_stats, on='book_id', how='left')
        
        # 3. –ü–†–ò–ó–ù–ê–ö–ò –ò–ó BOOKS.CSV
        if books is not None:
            df = df.merge(books, on='book_id', how='left')
            
            # –ü—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ –∫–Ω–∏–≥
            if 'publication_year' in df.columns:
                df['publication_year'] = df['publication_year'].fillna(1980)
                df['book_age'] = 2024 - df['publication_year']
                df['is_old_book'] = (df['book_age'] > 30).astype(int)
                df['is_recent_book'] = (df['book_age'] < 5).astype(int)
            
            if 'avg_rating' in df.columns:
                df['avg_rating_diff'] = df['avg_rating'] - df['book_mean']
        
        # 4. –ü–†–ò–ó–ù–ê–ö–ò –ò–ó USERS.CSV
        if users is not None:
            df = df.merge(users, on='user_id', how='left')
            
            if 'age' in df.columns:
                df['age'] = df['age'].fillna(df['age'].median())
                df['age_group'] = pd.cut(df['age'], bins=[0, 18, 25, 35, 50, 100], labels=[1, 2, 3, 4, 5])
            
            if 'gender' in df.columns:
                df['gender'] = df['gender'].fillna(1)
        
        # 5. –ü–†–ò–ó–ù–ê–ö–ò –ò–ó –ñ–ê–ù–†–û–í
        if book_genres is not None and genres is not None:
            # –°–∞–º—ã–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –∂–∞–Ω—Ä—ã
            genre_counts = book_genres['genre_id'].value_counts().head(10)
            top_genres = genre_counts.index
            
            for genre_id in top_genres:
                genre_name = genres[genres['genre_id'] == genre_id]['genre_name'].iloc[0] if len(genres[genres['genre_id'] == genre_id]) > 0 else f'genre_{genre_id}'
                genre_books = book_genres[book_genres['genre_id'] == genre_id]['book_id']
                df[f'is_{genre_name}'] = df['book_id'].isin(genre_books).astype(int)
        
        # 6. –û–°–ù–û–í–ù–´–ï –ü–†–ò–ó–ù–ê–ö–ò –ú–û–î–ï–õ–ò
        # User features
        df['user_confidence'] = np.log1p(df['user_count']) / 4.0
        df['user_generosity'] = (df['user_mean'] - self.global_mean) / max(self.global_std, 0.1)
        df['user_consistency'] = 1 / (1 + df['user_std'].fillna(1))
        
        # Book features
        df['book_popularity'] = np.log1p(df['book_count']) / 4.0
        df['book_controversial'] = (df['book_std'] > 2.0).astype(int)
        df['book_consistency'] = 1 / (1 + df['book_std'].fillna(1))
        
        # Interaction features
        df['mean_interaction'] = df['user_mean'] * df['book_mean'] / 10.0
        df['confidence_interaction'] = df['user_confidence'] * df['book_popularity']
        df['generosity_quality'] = df['user_generosity'] * df['book_mean']
        
        # Relative features
        df['user_mean_diff'] = df['user_mean'] - self.global_mean
        df['book_mean_diff'] = df['book_mean'] - self.global_mean
        df['combined_pred'] = 0.6 * df['user_mean'] + 0.4 * df['book_mean']
        
        # 7. –í–´–ë–û–† –§–ò–ù–ê–õ–¨–ù–´–• –ü–†–ò–ó–ù–ê–ö–û–í
        base_features = [
            # User features
            'user_mean', 'user_count', 'user_std', 'user_min', 'user_max', 'user_median',
            'user_confidence', 'user_generosity', 'user_consistency',
            
            # Book features  
            'book_mean', 'book_count', 'book_std', 'book_min', 'book_max', 'book_median',
            'book_popularity', 'book_controversial', 'book_consistency',
            
            # Interaction features
            'mean_interaction', 'confidence_interaction', 'generosity_quality',
            'user_mean_diff', 'book_mean_diff', 'combined_pred'
        ]
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
        additional_features = []
        if 'age' in df.columns:
            additional_features.extend(['age', 'age_group'])
        if 'gender' in df.columns:
            additional_features.append('gender')
        if 'publication_year' in df.columns:
            additional_features.extend(['publication_year', 'book_age', 'is_old_book', 'is_recent_book'])
        if 'avg_rating' in df.columns:
            additional_features.append('avg_rating_diff')
        
        # –ñ–∞–Ω—Ä–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        genre_features = [col for col in df.columns if col.startswith('is_')]
        
        all_features = base_features + additional_features + genre_features
        available_features = [f for f in all_features if f in df.columns]
        
        if is_train:
            self.feature_columns = available_features
            print(f"   üìä –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è {len(self.feature_columns)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        
        # –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤
        df[available_features] = df[available_features].fillna(0)
        
        return df[available_features]
    
    def train_champion_model(self, X, y):
        """–û–±—É—á–µ–Ω–∏–µ —á–µ–º–ø–∏–æ–Ω—Å–∫–æ–π –º–æ–¥–µ–ª–∏"""
        print("üéØ –û–ë–£–ß–ï–ù–ò–ï –ß–ï–ú–ü–ò–û–ù–°–ö–û–ô –ú–û–î–ï–õ–ò...")
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/validation
        X_train, X_val, y_train, y_val = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        print(f"   Train: {X_train.shape}, Val: {X_val.shape}")
        
        # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
        self.scalers['standard'] = StandardScaler()
        X_train_scaled = self.scalers['standard'].fit_transform(X_train)
        X_val_scaled = self.scalers['standard'].transform(X_val)
        
        # –ú–û–î–ï–õ–¨ 1: Gradient Boosting (–æ—Å–Ω–æ–≤–Ω–∞—è)
        print("   üöÄ –û–±—É—á–µ–Ω–∏–µ Gradient Boosting...")
        self.models['gb'] = GradientBoostingRegressor(
            n_estimators=200,
            learning_rate=0.1,
            max_depth=6,
            min_samples_split=50,
            min_samples_leaf=20,
            subsample=0.8,
            random_state=42
        )
        self.models['gb'].fit(X_train_scaled, y_train)
        
        # –ú–û–î–ï–õ–¨ 2: Random Forest
        print("   üå≤ –û–±—É—á–µ–Ω–∏–µ Random Forest...")
        self.models['rf'] = RandomForestRegressor(
            n_estimators=150,
            max_depth=10,
            min_samples_split=20,
            min_samples_leaf=10,
            random_state=42,
            n_jobs=-1
        )
        self.models['rf'].fit(X_train, y_train)
        
        # –ú–û–î–ï–õ–¨ 3: Ridge Regression
        print("   üìà –û–±—É—á–µ–Ω–∏–µ Ridge Regression...")
        self.models['ridge'] = Ridge(alpha=0.5, random_state=42)
        self.models['ridge'].fit(X_train_scaled, y_train)
        
        # –û–¶–ï–ù–ö–ê –ú–û–î–ï–õ–ï–ô
        print("\nüìä –û–¶–ï–ù–ö–ê –ú–û–î–ï–õ–ï–ô –ù–ê VALIDATION:")
        best_rmse = float('inf')
        best_model = None
        
        for name, model in self.models.items():
            if name == 'rf':
                preds = model.predict(X_val)
            else:
                preds = model.predict(X_val_scaled)
            
            rmse = np.sqrt(mean_squared_error(y_val, preds))
            mae = mean_absolute_error(y_val, preds)
            print(f"   {name.upper():12} - RMSE: {rmse:.4f}, MAE: {mae:.4f}")
            
            if rmse < best_rmse:
                best_rmse = rmse
                best_model = name
        
        print(f"   üèÜ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model.upper()} (RMSE: {best_rmse:.4f})")
        
        return X_train_scaled, y_train, X_val_scaled, y_val
    
    def predict_ensemble(self, X):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª–µ–º –º–æ–¥–µ–ª–µ–π"""
        if len(X) == 0:
            return np.array([self.global_mean] * len(X))
        
        X_scaled = self.scalers['standard'].transform(X)
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
        preds_gb = self.models['gb'].predict(X_scaled)
        preds_rf = self.models['rf'].predict(X)
        preds_ridge = self.models['ridge'].predict(X_scaled)
        
        # –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ (–±–æ–ª—å—à–µ –≤–µ—Å —É –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏)
        weights = {'gb': 0.5, 'rf': 0.3, 'ridge': 0.2}
        ensemble_pred = (
            weights['gb'] * preds_gb + 
            weights['rf'] * preds_rf + 
            weights['ridge'] * preds_ridge
        )
        
        return ensemble_pred
    
    def smart_post_processing(self, predictions, train_ratings):
        """–£–º–Ω–∞—è –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"""
        # 1. –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞
        predictions = np.clip(predictions, 1.0, 10.0)
        
        # 2. –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
        if len(train_ratings) > 0:
            pred_mean = np.mean(predictions)
            train_mean = np.mean(train_ratings)
            pred_std = np.std(predictions)
            train_std = np.std(train_ratings)
            
            # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ —Å—Ä–µ–¥–Ω–µ–≥–æ
            if abs(pred_mean - train_mean) > 0.05:
                adjustment = (train_mean - pred_mean) * 0.4
                predictions = predictions + adjustment
            
            # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –¥–∏—Å–ø–µ—Ä—Å–∏–∏
            if pred_std > 0 and train_std > 0:
                std_ratio = train_std / pred_std
                if 0.8 < std_ratio < 1.2:
                    centered = predictions - np.mean(predictions)
                    predictions = centered * (std_ratio ** 0.8) + np.mean(predictions)
        
        # 3. –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ
        predictions = np.clip(predictions, 1.0, 10.0)
        
        return predictions
    
    def run_champion_pipeline(self):
        """–ó–∞–ø—É—Å–∫ —á–µ–º–ø–∏–æ–Ω—Å–∫–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞"""
        print("üöÄ –ó–ê–ü–£–°–ö –ß–ï–ú–ü–ò–û–ù–°–ö–û–ì–û ML –ü–ê–ô–ü–õ–ê–ô–ù–ê")
        print("=" * 60)
        
        try:
            # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
            train, test, books, users, genres, book_genres, book_descriptions = self.load_all_data()
            
            if train is None:
                raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å train.csv")
            
            # 2. –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            print("\nüéØ –ü–û–î–ì–û–¢–û–í–ö–ê –¢–†–ï–ù–ò–†–û–í–û–ß–ù–´–• –î–ê–ù–ù–´–•...")
            X_train = self.create_comprehensive_features(train, books, users, book_genres, is_train=True)
            y_train = train[train['has_read'] == 1]['rating'] if 'has_read' in train.columns else train['rating']
            
            print(f"   üìä –§–∏–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {X_train.shape}")
            
            # 3. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
            self.train_champion_model(X_train, y_train)
            
            # 4. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ —Ç–µ—Å—Ç–µ
            if test is not None:
                print("\nüéØ –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ï –ù–ê –¢–ï–°–¢–û–í–´–• –î–ê–ù–ù–´–•...")
                X_test = self.create_comprehensive_features(test, books, users, book_genres, is_train=False)
                X_test = X_test.fillna(0)
                
                test_predictions = self.predict_ensemble(X_test)
                final_predictions = self.smart_post_processing(test_predictions, y_train)
                
                # 5. –°–æ–∑–¥–∞–Ω–∏–µ —Å–∞–±–º–∏—Ç–∞
                submission = test[['user_id', 'book_id']].copy()
                submission['rating_predict'] = final_predictions
                
                # 6. –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                self.analyze_champion_results(submission, y_train)
                
                # 7. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
                submission.to_csv('champion_ml_submission.csv', index=False)
                print(f"\nüíæ –ß–ï–ú–ü–ò–û–ù–°–ö–ò–ô –°–ê–ë–ú–ò–¢ –°–û–•–†–ê–ù–ï–ù: champion_ml_submission.csv")
                
                return submission
            else:
                print("‚ùå –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                return None
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤ ML –ø–∞–π–ø–ª–∞–π–Ω–µ: {e}")
            return None
    
    def analyze_champion_results(self, submission, train_ratings):
        """–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —á–µ–º–ø–∏–æ–Ω—Å–∫–æ–π –º–æ–¥–µ–ª–∏"""
        print("\nüìä –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –ß–ï–ú–ü–ò–û–ù–ê:")
        
        pred_stats = submission['rating_predict'].describe()
        train_stats = train_ratings.describe()
        
        print(f"   –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {pred_stats['min']:.3f} - {pred_stats['max']:.3f}")
        print(f"   –°—Ä–µ–¥–Ω–µ–µ: {pred_stats['mean']:.3f} (—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞: {train_stats['mean']:.3f})")
        print(f"   –ú–µ–¥–∏–∞–Ω–∞: {np.median(submission['rating_predict']):.3f} (—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞: {train_stats['50%']:.3f})")
        print(f"   –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {pred_stats['std']:.3f} (—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞: {train_stats['std']:.3f})")
        
        # –ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
        print(f"\n   üìà –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Ü–µ–Ω–æ–∫:")
        for threshold in [3, 5, 7, 9]:
            pred_pct = (submission['rating_predict'] >= threshold).mean() * 100
            train_pct = (train_ratings >= threshold).mean() * 100
            print(f"   ‚â•{threshold}: {pred_pct:5.1f}% (—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞: {train_pct:5.1f}%)")

# –ë–ï–ó–û–ü–ê–°–ù–´–ô –ó–ê–ü–£–°–ö
if __name__ == "__main__":
    print("üéØ –ß–ï–ú–ü–ò–û–ù–°–ö–û–ï ML –†–ï–®–ï–ù–ò–ï –î–õ–Ø –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø –†–ï–ô–¢–ò–ù–ì–û–í")
    print("üí° –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –í–°–ï –¥–æ—Å—Ç—É–ø–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:")
    print("   ‚Ä¢ train.csv + test.csv")
    print("   ‚Ä¢ books.csv (–º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∫–Ω–∏–≥)")
    print("   ‚Ä¢ users.csv (–º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π)") 
    print("   ‚Ä¢ genres.csv + book_genres.csv (–∂–∞–Ω—Ä—ã)")
    print("   ‚Ä¢ book_descriptions.csv (—Ç–µ–∫—Å—Ç–æ–≤—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è)")
    print("=" * 70)
    
    # –ó–∞–ø—É—Å–∫ —á–µ–º–ø–∏–æ–Ω—Å–∫–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è
    champion = ChampionMLPredictor()
    submission = champion.run_champion_pipeline()
    
    if submission is not None:
        print(f"\nüéâ –ß–ï–ú–ü–ò–û–ù–°–ö–û–ï ML –†–ï–®–ï–ù–ò–ï –£–°–ü–ï–®–ù–û –°–û–ó–î–ê–ù–û!")
        print("üì§ –û—Ç–ø—Ä–∞–≤–ª—è–π—Ç–µ: champion_ml_submission.csv")
        print("üöÄ –¶–ï–õ–ï–í–ê–Ø –ú–ï–¢–†–ò–ö–ê: 0.773+")
    else:
        print("\n‚ùå –ß–µ–º–ø–∏–æ–Ω—Å–∫–æ–µ —Ä–µ—à–µ–Ω–∏–µ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–æ")
        print("üí° –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —Ä–∞–±–æ—á–∏–µ —Ä–µ—à–µ–Ω–∏—è")
    
    print("üí™ –£–î–ê–ß–ò –í –°–û–†–ï–í–ù–û–í–ê–ù–ò–ò!")